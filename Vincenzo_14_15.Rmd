```{r}
library(recommenderlab)
library(dplyr)
library(ggplot2)
library(ggridges)
library(tidyr)
library(coop)
library(gridExtra)
```
Aufgabe: Reduziere den MovieLense Datensatz auf rund 400 Kunden 
und 700 Filme, indem du Filme und Kunden  mit sehr wenigen Ratings 
entfernst.
Untersuche und dokumentiere die Eigenschaften des reduzierten 
Datensatzes und beschreibe den Effekt der Datenreduktion:
  1.Anzahl Filme und Kunden sowie Sparsity vor und nach Datenreduktion
```{r}
data(MovieLense)
MovieLense_df <- as(MovieLense, "data.frame")
MovieLenseMeta_df <- as(MovieLenseMeta, "data.frame")
MOVIE_MIN_RATED = 700
USER_MIN_RATED = 400

movies_min_rated <- MovieLense_df %>%
  count(item) %>%
  arrange(desc(n)) %>%
  head(MOVIE_MIN_RATED) %>%
  select(item)

MovieLense_user_movies_reduced_df <- MovieLense_df %>%
  inner_join(movies_min_rated, by='item')

user_min_movies_rated <- MovieLense_user_movies_reduced_df %>%
  count(user) %>%
  arrange(desc(n)) %>%
  head(USER_MIN_RATED) %>%
  select(user)

MovieLense_user_movies_reduced_df <- MovieLense_user_movies_reduced_df %>%
  inner_join(user_min_movies_rated, by='user') 
```
```{r}
recommenderRegistry$get_entries(dataType = "realRatingMatrix")
# We have a few options

# Let's check some algorithms against each other
scheme <- recommenderlab::evaluationScheme(coerce(MovieLense_user_movies_reduced_df,MovieLense) , method = "split", train = 0.8,
                          given = 3, goodRating = 4)


algorithms <- list(
  "item-based CF" = list(name="IBCF", param=list(normalize = "Z-score"))
  
  )

# run algorithms, predict next n movies
results <- evaluate(scheme, algorithms, n=c(5, 10, 15, 20, 25, 30))

# Draw ROC curve
plot(results, annotate = 1:4, legend="topleft")

# See precision / recall
plot(results, "prec/rec", annotate=3)
```
```{r}
eval_reduced <- recommenderlab::evaluationScheme(data = coerce(MovieLense_user_movies_reduced_df, MovieLense), 
                                                 method="split", train=0.8, given=3)


IBCF_reduced <- Recommender(data = getData(eval_reduced, "train"), method = "IBCF", 
                            parameter = list(k = 30, method = "Cosine", na_as_zero=TRUE))

```


```{r}


top_n_to_df <- function(topn){
  #' @description Function to transform a TopNList object to a data.frame object.
  #' @param topn Topn List
  topn_df <- data.frame(user = sort(rep(1:length(top_n@items), top_n@n)), 
    rating = unlist(top_n@ratings), index = unlist(top_n@items))

  topn_df$item <- top_n@itemLabels[topn_df$index]
  topn_df$year <- MovieLenseMeta$year[topn_df$index]
  topn_df
}

calc_coverage <- function(top_n, n_movies=1664){
  #' @description Function, which returns coverage 
  #' @param top_n Top_n list generated by `recommenderlab::predict` as List.
  #' @param n_movies How many total movies there are. In the MovielenseDB, there are 1664 Movies.
  unique_pred_movies = unique(unlist(top_n, recursive = FALSE))
  n_unique_pred_movies = length(unique_pred_movies)
    
  return (n_unique_pred_movies / n_movies)
}

calc_popularity <- function(MovieLenseData, n_movies=1664){
  #' @description Function, which returns coverage as described here: https://ds-spaces.technik.fhnw.ch/6rsy/2021/05/02/recommender-system-evaluierung-coverage-und-novelty/
  #' @param MovieLenseData Movielense data.frame, containing how a user has rated a movie.
  #' @param n_movies How many total movies there are. In the MovielenseDB, there are 1664 Movies.
  
  popularity_movie <- MovieLenseData %>%
    count(item) %>%
    mutate(popularity = log2(n / n_movies)) %>%
    select(item, popularity)
  return (popularity_movie)
  
}
calc_novelty <- function(top_n, MovieLenseData, n_movies=1664){
  #' @description Function, which returns novelty as described here: https://ds-spaces.technik.fhnw.ch/6rsy/2021/05/02/recommender-system-evaluierung-coverage-und-novelty/
  #' @param top_n Top_n list generated by `recommenderlab::predict` as List.
  #' @param MovieLenseData MovieLense Dataset as data.frame
  #' @param n_movies How many total movies there are. In the MovielenseDB, there are 1664 Movies.
  popularity = calc_popularity(MovieLenseData, n_movies) 
  
  top_n_df <- top_n_to_df(top_n)
    
  group_size_user = top_n_df %>%
    group_by(user) %>%
    summarise(n = n()) %>%
    select(user, n)
  
  top_n_df <- top_n_df %>%
    left_join(group_size_user, by = 'user')
  
  top_n_popularity_df <- top_n_df %>%
    inner_join(popularity, by = 'item') %>%
    mutate(popularity = popularity / n)
  
  novelty = sum(top_n_popularity_df$popularity)
  
  S = length(unique(MovieLenseData$user))
  
  novelty = - 1 / S * novelty
  
  return (novelty)
}
```
```{r}
top_n = predict(object = IBCF_reduced, newdata = getData(eval_reduced, "unknown"), n = 15)
data.frame(getData(eval_reduced, "unknown"))
```
```{r}
calc_coverage(as(top_n, 'list'))
calc_novelty(top_n, MovieLense_df)
```


```{r}
avg_to_df <- function(evlist){
  #' @description gets the confusion matices from `evlist` and transforms it to a single data.frame
  #' @param evlist evaluationResultList
  #' @return data.frame confusion matrix with all recommenders as rec and number of recommendations as n
  evaluation_avg <- data.frame()
  for (i in 1:length(evlist)){
    current_avg <- as.data.frame(avg(evlist[i]))
    colnames(current_avg) <- c('TP','FP','FN','TN','N', 'precision','recall','TPR','FPR', 'n')
    current_avg$specificity <- current_avg$TN * (current_avg$TN + current_avg$FP)**-1
    current_avg$n <- rownames(current_avg)
    rownames(current_avg) <- NULL
    current_avg$rec <- names(evlist)[i]
    evaluation_avg <- rbind(evaluation_avg, current_avg)
  }
  return(evaluation_avg)
}
plot_percision_recall <- function(evaluation_avg){
  #' @description plots the percision recall curve with the according number of predictions
  #' @param evaluation_avg data.frame from avg_to_df
  ggplot(evaluation_avg, aes(x=precision, y=recall, label=n)) +
    geom_line(aes(color=rec)) +
    geom_text() +
    scale_color_manual(values=1:length(evaluation_avg)) +
    ggtitle('Precision Recall Curve') +
    xlab('precision') +
    ylab('recall')
}
```
```{r}
avg_to_df(results)
```
```{r}
plot_percision_recall(avg_to_df(results))
```
```{r}
test = as(getData(scheme, "unknown"), 'data.frame')
train =  as(getData(scheme, "known"), 'data.frame')
top_n = get_n_list(IBCF_reduced, getData(scheme, "unknown"), 15)
test = transform(test, user = as.numeric(user), item = as.character(item))
train = transform(train, user = as.numeric(user), item = as.character(item))
top_n = transform(top_n, user = as.numeric(user), item = as.character(item))

train$user_item <- paste(train$user, train$item)
test$user_item = paste(test$user, test$item)
top_n$user_item = paste(top_n$user, top_n$item)
test_top_n <- inner_join(test, top_n, by = "user_item")
```
```{r}
avg(results)
```
```{r}
comparison_top_10 <- function(data_train, data_known) {
  #' @description returns information about the overlap in top n lists from diy and reclab models
  #' @param data_train binarized realRatingMatrix as trainset
  #' @param data_known binarized realRatingMatrix as known testset

  # get 50 random customers
  rand_user <- sample(dimnames(data_known)[[1]], 50)
  sample_data_known <- data_known[rand_user]
  
  # get predictions for customers (diy and reclab)
  S <- similarity_jaccard(data_train, method = 'item')
  top_10_pred_diy <- top_10_prediction(P=predict_ibcf_binary(sample_data_known, S = S))
  
  IBCF_jac <-  Recommender(data_train, method = 'IBCF', param=list(method='Jaccard', k = 30))
  top_10_pred_rec <- as(predict(IBCF_jac, sample_data_known, n=10, params=list(minrating=1)), 'matrix')
  top_10_pred_rec <- pred_to_frame(top_10_pred_rec)
  
  # calculate overlap
  sum_inter <- nrow(intersect(select(top_10_pred_diy, 'user_id', 'movie'), select(top_10_pred_rec, 'user_id', 'movie')))
  prec <- sum_inter/nrow(top_10_pred_rec)
  print(paste('Overlap between diy and recommenderlab TopN: ', prec*100,'%')) 
  
  # compare recommendations to top x movies
  p <- as.data.frame(colMeans(data_train))
  colnames(p) <- c('avg_rating')
  top_10_movies <- rownames(as.data.frame(top_n(p, n = 10, wt = avg_rating)))
  
  b <- top_10_pred_diy$movie
  n_diy <- length(intersect(b, top_10_movies))
  print(paste('Number of Top Movies recommended with diy:',n_diy , 'out of 500 predictions'))
  
  a <- top_10_pred_rec$movie
  n_rec <- length(intersect(a, top_10_movies))
  print(paste('Number of Top Movies recommended with recommenderlab:',n_rec , 'out of 500 predictions'))
}
```

```{r}
test_top_n
```

